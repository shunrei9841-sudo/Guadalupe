{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKnxG8jbMXyzebphvf17R/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shunrei9841-sudo/Guadalupe/blob/main/Parcial%202-7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx5ywIaqmmIx",
        "outputId": "26faff8d-3d89-4665-8464-1e4f695d2b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- A) Simulación Simple ---\n",
            "Estimación P(X + Y > 2) (Simple): 0.533409\n",
            "Varianza del Estimador (Simple): 0.0000002489\n",
            "--------------------------------------------------\n",
            "--- B) Condicionamiento sobre X ---\n",
            "Estimación P(X + Y > 2) (Condicionamiento): 0.568314\n",
            "Varianza del Estimador (Condicionamiento): 0.0000000550\n",
            "Reducción de Varianza: 77.89%\n",
            "--------------------------------------------------\n",
            "--- C) Variable de Control C = X + Y ---\n",
            "E[X] = 1.3333, E[Y] = 1.0000, E[C] = 2.3333\n",
            "Valor óptimo b* (Muestra): 0.270461\n",
            "Estimación P(X + Y > 2) (Control): 0.532516\n",
            "Varianza del Estimador (Control): 0.0000001048\n",
            "Reducción de Varianza: 57.88%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import expon\n",
        "\n",
        "# --- Parámetros del Problema y Simulación ---\n",
        "lambda_Y = 1.0  # Parámetro de Y\n",
        "Threshold = 2.0 # Umbral de la suma (c = 2.0)\n",
        "N = 1000000     # Número de simulaciones\n",
        "\n",
        "# --- Generación de muestras ---\n",
        "U = np.random.uniform(0, 1, N)\n",
        "\n",
        "# Generar X: X = 2 * sqrt(U)\n",
        "X_samples = 2 * np.sqrt(U)\n",
        "\n",
        "# Generar Y: Y = -1/lambda_Y * log(1 - U)\n",
        "Y_samples = -1/lambda_Y * np.log(1 - U)\n",
        "\n",
        "# --- A) Simulación Simple (Monte Carlo Directo) ---\n",
        "print(\"--- A) Simulación Simple ---\")\n",
        "\n",
        "Sum_simple = X_samples + Y_samples\n",
        "indicator_simple = (Sum_simple > Threshold).astype(int)\n",
        "\n",
        "# Estimador P_hat = E[I(X + Y > c)]\n",
        "P_hat_simple = np.mean(indicator_simple)\n",
        "\n",
        "# Varianza del estimador simple\n",
        "Var_indicator_simple = np.var(indicator_simple, ddof=1)\n",
        "Var_P_hat_simple = Var_indicator_simple / N\n",
        "\n",
        "print(f\"Estimación P(X + Y > 2) (Simple): {P_hat_simple:.6f}\")\n",
        "print(f\"Varianza del Estimador (Simple): {Var_P_hat_simple:.10f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- B) Condicionamiento sobre X: E[I(X + Y > c) | X] ---\n",
        "print(\"--- B) Condicionamiento sobre X ---\")\n",
        "\n",
        "# Estimador de condicionamiento: E[I(X + Y > c)] = E[E[I(X + Y > c) | X]]\n",
        "# E[I(X + Y > c) | X=x] = P(Y > c - x | X=x)\n",
        "# Como X e Y son independientes: P(Y > c - x)\n",
        "\n",
        "# P(Y > c - x) es la Función de Supervivencia (SF) de Y evaluada en (c - x):\n",
        "# S_Y(c - x) = exp(-lambda_Y * (c - x)), para c - x > 0 (es decir, x < c)\n",
        "# Si x >= c, P(Y > c - x) = P(Y > negativo) = 1.\n",
        "\n",
        "# 1. Usamos las mismas muestras X_samples\n",
        "X_cond = X_samples\n",
        "c = Threshold\n",
        "\n",
        "# 2. Calcular el estimador condicional g_cond(X) = E[I(X + Y > c) | X]\n",
        "g_cond_X = np.zeros(N)\n",
        "\n",
        "# Caso 1: x < c (x < 2). P(Y > c - x) = exp(-(c - x))\n",
        "idx_lt_c = X_cond < c\n",
        "g_cond_X[idx_lt_c] = np.exp(-lambda_Y * (c - X_cond[idx_lt_c]))\n",
        "\n",
        "# Caso 2: x >= c (x >= 2). P(Y > c - x) = 1 (ya que c - x <= 0)\n",
        "idx_ge_c = X_cond >= c\n",
        "g_cond_X[idx_ge_c] = 1.0\n",
        "\n",
        "# 3. Estimar la probabilidad P(X + Y > 2) con el estimador condicional\n",
        "P_hat_cond = np.mean(g_cond_X)\n",
        "\n",
        "# 4. Calcular la varianza del estimador condicional\n",
        "Var_g_cond_X = np.var(g_cond_X, ddof=1)\n",
        "Var_P_hat_cond = Var_g_cond_X / N\n",
        "\n",
        "# 5. Porcentaje de Reducción de Varianza\n",
        "Reduccion_cond = (Var_P_hat_simple - Var_P_hat_cond) / Var_P_hat_simple * 100\n",
        "\n",
        "print(f\"Estimación P(X + Y > 2) (Condicionamiento): {P_hat_cond:.6f}\")\n",
        "print(f\"Varianza del Estimador (Condicionamiento): {Var_P_hat_cond:.10f}\")\n",
        "print(f\"Reducción de Varianza: {Reduccion_cond:.2f}%\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- C) Variable de Control: C = X + Y ---\n",
        "print(\"--- C) Variable de Control C = X + Y ---\")\n",
        "\n",
        "# El estimador de la variable de control es: g_ctrl = g(X, Y) - b * (C - E[C])\n",
        "# Donde g(X, Y) = I(X + Y > c) y C = X + Y.\n",
        "# El valor esperado E[C] es conocido: E[C] = E[X] + E[Y].\n",
        "\n",
        "# 1. Calcular E[X] y E[Y] analíticamente\n",
        "# E[Y] = 1/lambda_Y = 1/1 = 1.0\n",
        "E_Y_analytic = 1.0\n",
        "\n",
        "# E[X] = Integral de x * f(x) dx de 0 a 2\n",
        "# E[X] = Integral de x * (x/2) dx = Integral de (x^2/2) dx de 0 a 2\n",
        "# E[X] = [x^3/6]_0^2 = 8/6 = 4/3 ≈ 1.333333\n",
        "E_X_analytic = 4/3\n",
        "\n",
        "# E[C] = E[X] + E[Y]\n",
        "E_C_analytic = E_X_analytic + E_Y_analytic\n",
        "\n",
        "# 2. Calcular el factor b* óptimo (usando valores muestrales)\n",
        "# b* = Cov[g(X, Y), C] / Var[C]\n",
        "g_XY = indicator_simple # Estimador de interés\n",
        "C_samples = Sum_simple   # Variable de control\n",
        "\n",
        "# Calcular Cov[g(XY), C]\n",
        "Cov_matrix = np.cov(g_XY, C_samples)\n",
        "Cov_gXY_C = Cov_matrix[0, 1]\n",
        "\n",
        "# Calcular Var[C]\n",
        "Var_C_sample = np.var(C_samples, ddof=1)\n",
        "\n",
        "# Calcular el factor b* óptimo\n",
        "b_optimo = Cov_gXY_C / Var_C_sample\n",
        "\n",
        "# 3. Calcular el estimador g_ctrl\n",
        "g_ctrl = g_XY - b_optimo * (C_samples - E_C_analytic)\n",
        "\n",
        "# 4. Estimar la probabilidad P(X + Y > 2) con el estimador de control\n",
        "P_hat_ctrl = np.mean(g_ctrl)\n",
        "\n",
        "# 5. Calcular la varianza del estimador de control\n",
        "Var_g_ctrl = np.var(g_ctrl, ddof=1)\n",
        "Var_P_hat_ctrl = Var_g_ctrl / N\n",
        "\n",
        "# 6. Porcentaje de Reducción de Varianza\n",
        "Reduccion_ctrl = (Var_P_hat_simple - Var_P_hat_ctrl) / Var_P_hat_simple * 100\n",
        "\n",
        "print(f\"E[X] = {E_X_analytic:.4f}, E[Y] = {E_Y_analytic:.4f}, E[C] = {E_C_analytic:.4f}\")\n",
        "print(f\"Valor óptimo b* (Muestra): {b_optimo:.6f}\")\n",
        "print(f\"Estimación P(X + Y > 2) (Control): {P_hat_ctrl:.6f}\")\n",
        "print(f\"Varianza del Estimador (Control): {Var_P_hat_ctrl:.10f}\")\n",
        "print(f\"Reducción de Varianza: {Reduccion_ctrl:.2f}%\")"
      ]
    }
  ]
}